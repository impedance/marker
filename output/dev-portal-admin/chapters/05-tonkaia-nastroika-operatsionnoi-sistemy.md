## 5 Тонкая настройка операционной системы

Для управления параметрами ядра Linux в реальном времени и при запуске ОС применяются различные инструменты. Их использование позволяет упростить администрирование и повысить предсказуемость поведения компонентов Комплекса.

В пунктах 5.1.1.1-5.1.1.3 рассмотрены доступные утилиты и инструменты для настройки параметров ядра с примерами их эффективного использования. Использование этих инструментов способствует стабильной и эффективной работе компонентов Комплекса в продуктивной среде.

### 5.1 Рекомендованные настройки производительности

sysctl – основная утилита для чтения и изменения параметров ядра. Она взаимодействует с каталогом /proc/sys/, где доступны все системные параметры.

В качестве примера настройки параметров утилитой, чтобы изменить параметр net.core.somaxconn, который отвечает за максимальное число соединений в очереди для принятия сокетом, можно использовать следующую команду:

sysctl -w net.core.somaxconn=1024

Для сохранения настроек нужно добавить строку в файл /etc/sysctl.conf (или создать отдельный файл в /etc/sysctl.d/) со следующим содержанием:

net.core.somaxconn = 1024

#### 5.1.1 Инструменты настройки ядра

Tuned – утилита для применения готовых и пользовательских профилей оптимизации и динамической адаптивной настройки ОС. Она включает профили, ориентированные на разные типы нагрузки (например, throughput-performance, latency-performance).

Установка утилиты производится командами:

yum install tuned # Для ОС на основе RHEL

apt-get install tuned # Для ОС на основе Debian

Для активации профиля нужно ввести:

tuned-adm profile throughput-performance

Процесс создания пользовательского профиля для Kubernetes состоит из выполнения следующих команд:

создать каталог для профиля:

mkdir /etc/tuned/kubernetes-optimize

создать файл tuned.conf со следующими настройками:

[main]

include=throughput-performance

[sysctl]

net.ipv4.ip_local_port_range = 10240 65535

net.core.somaxconn = 1024

net.ipv4.tcp_max_syn_backlog = 2048

активировать профиль:

tuned-adm profile kubernetes-optimize

ktune

Утилита ktune из пакета tuned применяет пользовательские параметры настройки ОС при запуске на основе выбранного профиля. Хотя ktune реже используется в современных дистрибутивах, понимание его роли помогает оценить эволюцию автоматических решений для настройки ОС.

##### 5.1.1.1 sysctl

Утилиты numactl и numad используются для ОС с неравномерным доступом к памяти (NUMA). Эти инструменты управляют политиками распределения памяти и привязкой к процессорам, что особенно важно для приложений, интенсивно использующих память.

Утилита cpufrequtils позволяет управлять политиками масштабирования частоты процессора, что помогает оптимизировать энергопотребление и производительность в зависимости от характеристик нагрузки.

Демон irqbalance распределяет аппаратные прерывания между процессорами в многопроцессорной операционной системе. Это повышает производительность для приложений с высокой интенсивностью ввода-вывода, избегая перегрузки одного процессора.

##### 5.1.1.2 Tuned

Для повышения производительности сетевой подсистемы ОС рекомендуется изменить ряд параметров ядра Linux. Настройка данных параметров позволяет снизить задержки при установлении соединений, расширить допустимое количество одновременных подключений и предотвратить исчерпание доступных портов при загруженном сетевом взаимодействии.

Для настройки производительности сетевых параметров в кластерах Kubernetes с высокой нагрузкой рекомендуется внести изменения в следующие параметры из таблицы 5.

Таблица 5 – Настройка сетевых параметров в кластерах Kubernetes

##### 5.1.1.3 Дополнительные утилиты

После применения настроек рекомендуется контролировать их влияние на производительность ОС. Для анализа состояния сетевых соединений и очередей можно использовать следующие утилиты:

netstat — отображение активных подключений и статистики по протоколам;

ss — более современный аналог netstat с поддержкой фильтрации;

ipvsadm — просмотр состояния балансировщиков при использовании IP Virtual Server.

Рекомендуется производить изменения параметров поэтапно, контролируя метрики нагрузки и стабильности работы. Оптимальные значения могут варьироваться в зависимости от характеристик оборудования и типа размещения Комплекса.

#### 5.1.2 Сетевые параметры

Эффективное управление оперативной памятью критически важно для обеспечения стабильной работы узлов, особенно в условиях высокой нагрузки и большого количества запущенных контейнеров. ОС Linux предоставляет ряд параметров, позволяющих гибко управлять распределением памяти и поведением ОС при её нехватке.

Для настройки параметров управления памятью рекомендуется использовать значения, приведённые в таблице 6Ошибка! Источник ссылки не найден..

Таблица 6 – Рекомендуемые параметры управления памятью

Все настройки необходимо применять с учётом объема доступной памяти и характера нагрузок на узлы, проводя предварительное тестирование в пилотной среде.

#### 5.1.3 Мониторинг и корректировка параметров

Корректная настройка параметров работы с файловой системой и вводом-выводом позволяет обеспечить стабильную работу компонентов Комплекса, интенсивно взаимодействующих с хранилищем данных. Это особенно актуально для компонентов, работающих с журналируемыми данными, логами и временными файлами.

Рекомендуется выполнить настройку параметров, указанных в таблице 7.

Таблица 7 – Параметры файловой системы и ввода-вывода

Рекомендуется использовать соответствующие udev-правила или скрипты инициализации, чтобы выбранный планировщик применялся автоматически при запуске ОС.

#### 5.1.4 Управление памятью

После применения настроек файловой системы и параметров дискового ввода-вывода (см. раздел 5.1.5) необходимо контролировать их влияние на производительность. Для оценки используются стандартные инструменты мониторинга, такие как:

iostat — анализирует статистику по дисковому вводу-выводу;

iotop — отслеживает текущую активность ввода-вывода процессов;

sar —собирает и отображает статистику производительности различных подсистем ОС.

Кроме того, Kubernetes предоставляет встроенные метрики и журналы, позволяющие анализировать I/O-паттерны приложений. Это обеспечивает возможность адаптировать параметры под реальные рабочие нагрузки и добиться устойчивой производительности компонентов Комплекса.

#### 5.1.5 Оптимизация файловой системы и дискового ввода-вывода

Параметры планировщика процессов ядра Linux оказывают прямое влияние на производительность и отклик приложений в среде Kubernetes, особенно в условиях высокой конкуренции за ресурсы CPU. Рекомендуется внести следующие настройки в параметры ядра, указанные в таблице 8.

Таблица 8 – Параметры настройки планирования процессов

Применение вышеуказанных параметров требует предварительного тестирования в условиях, приближенных к промышленной среде, и регулярного анализа нагрузки на CPU.

#### 5.1.6 Мониторинг и корректировка параметров ввода-вывода

Для повышения производительности и предсказуемости работы критически важных компонентов в составе Портала разработчика может применяться привязка контейнеров к определённым процессорным ядрам (CPU pinning), а также управление распределением ресурсов процессора с использованием средств Kubernetes.

Конфигурации развертывания Kubernetes описываются в pod – наименьшей единице развертывания в Kubernetes, задаются в формате YAML (реже — JSON). Параметры pod определяют, какие контейнеры запускаются и какие ресурсы они используют, какие политики применяются и как организовано взаимодействие с другими элементами ОС.

Kubernetes предоставляет следующие механизмы управления ресурсами CPU:

привязка контейнеров к конкретным процессорам (CPU pinning);

использование наборов процессоров (CPU sets);

указание запросов и ограничений на использование CPU (параметры requests и limits в спецификации pod).

Такие настройки особенно актуальны для компонентов, чувствительных к задержкам или требующих высокой вычислительной мощности, поскольку позволяют:

исключить миграцию процессов между ядрами;

повысить эффективность кеширования;

сократить накладные расходы на переключение контекста;

обеспечить размещение модулей ближе к необходимым узлам NUMA.

Пример спецификации pod с указанием ресурсов и узловой привязки:

apiVersion: v1

kind: Pod

metadata:

name: cpu-affinity-example

spec:

containers:

- name: container1

image: nginx

resources:

requests:

cpu: "2"

limits:

cpu: "4"

affinity:

nodeAffinity:

requiredDuringSchedulingIgnoredDuringExecution:

nodeSelectorTerms:

- matchExpressions:

- key: kubernetes.io/e2e-az-name

operator: In

values:

- e2e-az1

- e2e-az2

Данный фрагмент демонстрирует задание минимального (requests) и максимального (limits) количества CPU для контейнера, а также настройку привязки к определённым зонам доступности. Это позволяет Kubernetes запланировать выполнение пода на узле, соответствующем заданным условиям, и тем самым обеспечить требуемый уровень производительности.

#### 5.1.7 Планирование процессов

Для анализа нагрузки на CPU применяются как стандартные утилиты, так и специализированные средства мониторинга в рамках Kubernetes:

htop, mpstat — отслеживают использование процессоров и процессов;

Prometheus и Grafana — используются для сбора и визуализации метрик кластера.

Регулярный мониторинг позволяет выявить узкие места и провести корректировку конфигурации, учитывая характеристики архитектуры и тип рабочих нагрузок.

#### 5.1.8 Привязка к процессору и управление CPU

#### 5.1.9 Мониторинг использования CPU и корректировка

Для обеспечения безопасности и отказоустойчивости все компоненты Комплекса запускаются в отдельных контейнерах. Это обеспечивает изоляцию процессов и снижает риск того, что сбой или компрометация одного из компонентов повлияет на работу остальных.

Для повышения уровня безопасности рекомендуется выполнять следующие настройки по изоляции контейнеров:

создавать изолированную внутреннюю сеть Docker (bridge), в которой взаимодействуют только контейнеры Комплекса;

ограничивать сетевой доступ к каждому контейнеру, разрешая только необходимые порты:

PostgreSQL: доступ разрешён только из контейнеров, выполняющих PHP-код;

Redis: доступен только из контейнера с приложением;

устанавливать лимиты на использование ресурсов (CPU и память) для каждого контейнера, чтобы предотвратить избыточное потребление и влияние одного контейнера на другие.

### 5.2 Рекомендованные настройки безопасности

Передача данных между пользователем и сервером осуществляется по защищённым TLS-соединениям. Рекомендуется использовать следующие настройки:

все входящие соединения обрабатываются по протоколу TLS версии 1.2 или 1.3;

TLS-сертификаты настраиваются и обновляются автоматически через Traefik;

в незашифрованный порт (80) осуществляется только перенаправление на HTTPS (порт 443).

#### 5.2.1 Изоляция процессов и данных

Для защиты сетевой инфраструктуры следует настроить брандмауэр следующим образом:

разрешить только следующие порты:

80/tcp — перенаправление HTTP-запросов на HTTPS;

443/tcp — основной порт для защищённого взаимодействия с системой;

все остальные порты должны быть закрыты. Попытки соединения через другие порты должны блокироваться.

#### 5.2.2 Шифрование

Система логирования настраивается для всех компонентов Комплекса с целью обеспечения наблюдаемости и возможности оперативного реагирования на возникающие ошибки.

На уровне приложения логирование конфигурируется через переменную окружения LOG_CHANNEL. Поддерживаются следующие режимы:

stack / single — непрерывная запись логов в один файл;

daily — создание отдельного файла для каждого дня; файлы хранятся до 14 суток;

syslog — отправка логов в системный журнал;

null — отключение логирования.

Логи приложения сохраняются в каталоге storage/logs. Кроме того, все записи логов доступны для просмотра в административной панели CMS в разделе "Система → Журнал событий" (/backend/system/eventlogs).

#### 5.2.3 Брандмауэр

Для обеспечения бесперебойной работы Портала разработчика требуется соблюдать ряд мер по мониторингу и диагностике. Администратору Комплекса следует своевременно выявлять отклонения в работе служб, предотвращать потерю данных и оперативно реагировать на сбои.

В данной главе приведены рекомендации по обеспечению устойчивого функционирования Комплекса, включая правила хранения постоянных данных, создание резервных копий и настройку системы мониторинга.

### 5.3 Логирование

Поскольку работа Комплекса развёрнута в изолированных контейнерах Docker, для мониторинга состояния компонентов и выявления сбоев реализовано централизованное логирование через стандартный поток вывода (stdout) каждого контейнера. Это позволяет фиксировать события выполнения и обеспечивать оперативный доступ к журналам.

Для получения информации о состоянии запущенных контейнеров и анализа логов используются стандартные команды Docker. В таблице 9 приведён перечень типовых команд и описание их выводов.

Таблица 9 – Типовые команды управления контейнерами Docker